# coding: utf-8

"""
    STACKIT Observability API

    API endpoints for Observability on STACKIT

    The version of the OpenAPI document: 1.1.1
    Contact: stackit-argus@mail.schwarz
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501 docstring might be too long

from __future__ import annotations

import json
import pprint
from typing import Any, ClassVar, Dict, List, Optional, Set

from pydantic import BaseModel, ConfigDict, Field
from typing_extensions import Annotated, Self


class UpdateMetricsStorageRetentionPayload(BaseModel):
    """
    UpdateMetricsStorageRetentionPayload
    """

    metrics_retention_time1h: Annotated[str, Field(min_length=2, strict=True, max_length=8)] = Field(
        description="Retention time of longtime storage of 1h sampled data. After that time the data will be deleted permanently. `Additional Validators:` * Should be a valid time string * Should not be bigger than metricsRetentionTime5m",
        alias="metricsRetentionTime1h",
    )
    metrics_retention_time5m: Annotated[str, Field(min_length=2, strict=True, max_length=8)] = Field(
        description="Retention time of longtime storage of 5m sampled data. After that time the data will be down sampled to 1h. `Additional Validators:` * Should be a valid time string * Should not be bigger than metricsRetentionTimeRaw",
        alias="metricsRetentionTime5m",
    )
    metrics_retention_time_raw: Annotated[str, Field(min_length=2, strict=True, max_length=8)] = Field(
        description="Retention time of longtime storage of raw sampled data. After that time the data will be down sampled to 5m. Keep in mind, that the initial goal of downsampling is not saving disk or object storage space. In fact, downsampling doesn't save you any space but instead, it adds 2 more blocks for each raw block which are only slightly smaller or relatively similar size to raw block. This is done by internal downsampling implementation which to be mathematically correct holds various aggregations. This means that downsampling can increase the size of your storage a bit (~3x), if you choose to store all resolutions (recommended). The goal of downsampling is to provide an opportunity to get fast results for range queries of big time intervals like months or years. `Additional Validators:` * Should be a valid time string * Should not be bigger than 13 months",
        alias="metricsRetentionTimeRaw",
    )
    __properties: ClassVar[List[str]] = ["metricsRetentionTime1h", "metricsRetentionTime5m", "metricsRetentionTimeRaw"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of UpdateMetricsStorageRetentionPayload from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of UpdateMetricsStorageRetentionPayload from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "metricsRetentionTime1h": obj.get("metricsRetentionTime1h"),
                "metricsRetentionTime5m": obj.get("metricsRetentionTime5m"),
                "metricsRetentionTimeRaw": obj.get("metricsRetentionTimeRaw"),
            }
        )
        return _obj
